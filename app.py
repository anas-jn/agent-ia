# ğŸ“¦ Imports
import streamlit as st
import io
from PyPDF2 import PdfReader
from docx import Document
from fpdf import FPDF

# ğŸ§  LangChain
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.chains.question_answering import load_qa_chain

# âš™ï¸ Configuration
st.set_page_config(page_title="Portfolio IA - Anas",
                   page_icon="ğŸ¤–", layout="wide")
if "pitch_text" not in st.session_state:
    st.session_state.pitch_text = ""

# ğŸ¨ Branding
st.sidebar.image("assets/logo.jpg", width=120)
st.sidebar.markdown("## ğŸ§­ Navigation IA")
menu = st.sidebar.radio("ğŸ“‚ Modules disponibles :", [
    "ğŸ  Accueil - Agent IA Chat",
    "ğŸ“„ Analyse de CV PDF",
    "âš¡ Pitch Express",
    "ğŸ§  GÃ©nÃ©rateur de quiz ",
    "ğŸ’¬ Agent support client",
    "ğŸ“„ Analyse juridique IA",
    "â“ FAQ intelligente"
    
])
st.sidebar.markdown("---")
st.sidebar.markdown("ğŸ‘¤ [Profil GitHub](https://github.com/anasjannaj)")
st.sidebar.markdown("ğŸ“¬ Contact : anas@example.com")

# ğŸ  Agent IA Chat
if menu == "ğŸ  Accueil - Agent IA Chat":
    st.title("ğŸ’¬ Agent IA - Chat GÃ©nÃ©ral")
    user_input = st.text_input("ğŸ—¨ï¸ Votre question")
    if user_input:
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)
        response = llm.predict(user_input)
        st.markdown("### ğŸ¤– RÃ©ponse")
        st.success(response)

# ğŸ“„ Analyse de CV PDF
elif menu == "ğŸ“„ Analyse de CV PDF":
    st.title("ğŸ“„ Analyse de CV PDF")
    pdf = st.file_uploader("ğŸ“„ Fichier PDF", type="pdf")
    if pdf:
        reader = PdfReader(pdf)
        raw_text = "".join([page.extract_text() for page in reader.pages])
        splitter = CharacterTextSplitter(
            separator="\n", chunk_size=1000, chunk_overlap=200)
        chunks = splitter.split_text(raw_text)
        embeddings = OpenAIEmbeddings()
        db = FAISS.from_texts(chunks, embedding=embeddings)

        st.markdown("### ğŸ’¡ Suggestions rapides")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“Œ CompÃ©tences principales"):
                st.session_state["question"] = "Quelles sont les compÃ©tences principales du candidat ?"
            if st.button("ğŸ§  ExpÃ©rience pertinente"):
                st.session_state["question"] = "Quelle est l'expÃ©rience la plus pertinente ?"
            if st.button("ğŸ¯ Matching IA"):
                st.session_state["question"] = "Ce profil correspond-il Ã  un poste de dÃ©veloppeur IA ?"
        with col2:
            if st.button("ğŸ“ˆ Points forts & faibles"):
                st.session_state["question"] = "Quels sont les points forts et axes d'amÃ©lioration ?"
            if st.button("ğŸ“ RÃ©sumÃ© professionnel"):
                st.session_state["question"] = "GÃ©nÃ¨re un rÃ©sumÃ© professionnel du CV."

        question = st.text_input(
            "â“ Posez votre question ici", value=st.session_state.get("question", ""))
        if question:
            docs = db.similarity_search(question)
            llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
            chain = load_qa_chain(llm, chain_type="stuff")
            response = chain.run(input_documents=docs, question=question)
            st.markdown("### ğŸ§  RÃ©ponse IA")
            st.success(response)

            format = st.selectbox("ğŸ“ Choisissez le format de tÃ©lÃ©chargement :", [
                                  "TXT", "DOCX", "PDF"])
            if format == "TXT":
                st.download_button("ğŸ“¥ TÃ©lÃ©charger en TXT",
                                   data=response, file_name="reponse.txt")
            elif format == "DOCX":
                doc = Document()
                doc.add_paragraph(response)
                buffer = io.BytesIO()
                doc.save(buffer)
                buffer.seek(0)
                st.download_button("ğŸ“¥ TÃ©lÃ©charger en DOCX",
                                   data=buffer, file_name="reponse.docx")
            elif format == "PDF":
                pdf_file = FPDF()
                pdf_file.add_page()
                pdf_file.set_font("Arial", size=12)
                for line in response.split('\n'):
                    pdf_file.cell(200, 10, txt=line, ln=True)
                pdf_output = io.BytesIO(
                    pdf_file.output(dest='S').encode('latin-1'))
                st.download_button("ğŸ“¥ TÃ©lÃ©charger en PDF",
                                   data=pdf_output, file_name="reponse.pdf")
    else:
        st.info("ğŸ“„ TÃ©lÃ©verse un fichier PDF pour commencer.")

# âš¡ Pitch Express
elif menu == "âš¡ Pitch Express":
    st.title("âš¡ Pitch Express")
    pdf = st.file_uploader("ğŸ“„ Fichier PDF", type="pdf")
    st.markdown("RÃ©sumÃ© rapide de ton profil en 30 secondes.")
    if pdf and st.button("ğŸ¤ GÃ©nÃ©rer le pitch"):
        reader = PdfReader(pdf)
        raw_text = "".join([page.extract_text() for page in reader.pages])
        prompt = f"Fais un rÃ©sumÃ© professionnel et percutant du profil suivant :\n{raw_text}\nRÃ©sumÃ© en 30 secondes."
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.5)
        pitch = llm.predict(prompt)
        st.session_state.pitch_text = pitch

    if st.session_state.pitch_text:
        st.markdown("### ğŸ¯ RÃ©sumÃ© Express")
        st.info(st.session_state.pitch_text)
        format = st.selectbox("ğŸ“ Format de tÃ©lÃ©chargement :", [
                              "TXT", "DOCX", "PDF"])
        if format == "TXT":
            st.download_button("ğŸ“¥ TÃ©lÃ©charger le pitch (TXT)",
                               data=st.session_state.pitch_text, file_name="pitch_express.txt")
        elif format == "DOCX":
            doc = Document()
            doc.add_paragraph(st.session_state.pitch_text)
            buffer = io.BytesIO()
            doc.save(buffer)
            buffer.seek(0)
            st.download_button("ğŸ“¥ TÃ©lÃ©charger le pitch (DOCX)",
                               data=buffer, file_name="pitch_express.docx")
        elif format == "PDF":
            pdf_file = FPDF()
            pdf_file.add_page()
            pdf_file.set_font("Arial", size=12)
            for line in st.session_state.pitch_text.split('\n'):
                pdf_file.cell(200, 10, txt=line, ln=True)
            pdf_output = io.BytesIO(
                pdf_file.output(dest='S').encode('latin-1'))
            st.download_button("ğŸ“¥ TÃ©lÃ©charger le pitch (PDF)",
                               data=pdf_output, file_name="pitch_express.pdf")
    elif not pdf:
        st.info("ğŸ“„ TÃ©lÃ©verse un fichier PDF pour gÃ©nÃ©rer ton pitch.")


# ğŸ§  GÃ©nÃ©rateur de quiz IA
elif menu == "ğŸ§  GÃ©nÃ©rateur de quiz ":
    st.title("ğŸ§  GÃ©nÃ©rateur de quiz IA")
    pdf = st.file_uploader("ğŸ“„ Fichier source", type="pdf")

    if pdf and st.button("ğŸ“ GÃ©nÃ©rer des questions"):
        reader = PdfReader(pdf)
        raw_text = "".join([page.extract_text() for page in reader.pages])
        prompt = f"GÃ©nÃ¨re 5 questions Ã  choix multiples sur ce contenu :\n{raw_text}"
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)
        quiz = llm.predict(prompt)
        st.session_state.quiz_text = quiz

    if "quiz_text" in st.session_state and st.session_state.quiz_text:
        st.markdown("### ğŸ“‹ Quiz gÃ©nÃ©rÃ©")
        st.write(st.session_state.quiz_text)

        format = st.selectbox("ğŸ“ Format de tÃ©lÃ©chargement :", [
                              "TXT", "DOCX", "PDF"])
        if format == "TXT":
            st.download_button("ğŸ“¥ TÃ©lÃ©charger le quiz (TXT)",
                               data=st.session_state.quiz_text, file_name="quiz_ia.txt")
        elif format == "DOCX":
            doc = Document()
            doc.add_paragraph(st.session_state.quiz_text)
            buffer = io.BytesIO()
            doc.save(buffer)
            buffer.seek(0)
            st.download_button("ğŸ“¥ TÃ©lÃ©charger le quiz (DOCX)",
                               data=buffer, file_name="quiz_ia.docx")
        elif format == "PDF":
            pdf_file = FPDF()
            pdf_file.add_page()
            pdf_file.set_font("Arial", size=12)
            for line in st.session_state.quiz_text.split('\n'):
                pdf_file.cell(200, 10, txt=line, ln=True)
            pdf_output = io.BytesIO(
                pdf_file.output(dest='S').encode('latin-1'))
            st.download_button("ğŸ“¥ TÃ©lÃ©charger le quiz (PDF)",
                               data=pdf_output, file_name="quiz_ia.pdf")


# ğŸ’¬ Agent support client


elif menu == "ğŸ’¬ Agent support client":
    st.title("ğŸ’¬ Agent IA - Support Client")
    context = st.text_area("ğŸ“ Contexte produit/service",
                           "Notre entreprise vend des logiciels de gestion pour PME...")
    question = st.text_input("â“ Question du client")

    if question:
        prompt = f"Voici le contexte produit/service : {context}\nRÃ©ponds Ã  la question suivante : {question}"
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)
        response = llm.predict(prompt)
        st.markdown("### ğŸ¤– RÃ©ponse IA")
        st.success(response)

        format = st.selectbox("ğŸ“ Format de tÃ©lÃ©chargement :", [
                              "TXT", "DOCX", "PDF"])
        if format == "TXT":
            st.download_button("ğŸ“¥ TÃ©lÃ©charger la rÃ©ponse (TXT)",
                               data=response, file_name="reponse_support.txt")
        elif format == "DOCX":
            doc = Document()
            doc.add_paragraph(response)
            buffer = io.BytesIO()
            doc.save(buffer)
            buffer.seek(0)
            st.download_button("ğŸ“¥ TÃ©lÃ©charger la rÃ©ponse (DOCX)",
                               data=buffer, file_name="reponse_support.docx")
        elif format == "PDF":
            pdf_file = FPDF()
            pdf_file.add_page()
            pdf_file.set_font("Arial", size=12)
            for line in response.split('\n'):
                pdf_file.cell(200, 10, txt=line, ln=True)
            pdf_output = io.BytesIO(
                pdf_file.output(dest='S').encode('latin-1'))
            st.download_button("ğŸ“¥ TÃ©lÃ©charger la rÃ©ponse (PDF)",
                               data=pdf_output, file_name="reponse_support.pdf")


# â“ FAQ intelligente
elif menu == "â“ FAQ intelligente":
    st.title("â“ FAQ intelligente")
    faq_input = st.text_input("ğŸ’¬ Pose ta question sur le profil dâ€™Anas")
    if faq_input:
        context = """
        Anas Jannaj est dÃ©veloppeur digital, spÃ©cialisÃ© en Python, Flutter, IA, Streamlit, Supabase.
        Il a crÃ©Ã© jimla.ma, des LMS, des gÃ©nÃ©rateurs de quiz IA.
        Il vise une carriÃ¨re freelance avec des outils locaux et puissants.
        Il est basÃ© au Maroc, parle franÃ§ais et anglais, et est trÃ¨s actif dans lâ€™apprentissage rapide.
        """
        prompt = f"Voici le contexte : {context}\nRÃ©ponds Ã  cette question : {faq_input}"
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.5)
        response = llm.predict(prompt)
        st.markdown("### ğŸ¤– RÃ©ponse IA")
        st.success(response)
